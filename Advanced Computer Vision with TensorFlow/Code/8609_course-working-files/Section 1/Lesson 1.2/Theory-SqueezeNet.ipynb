{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SqueezeNet Architecture Design\n",
    "*by Marvin Bertin*\n",
    "<img src=\"../../images/keras-tensorflow-logo.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SqueezeNet\n",
    "\n",
    "**What is SqueezeNet?**\n",
    "- a deep convolutional neural network (CNN)\n",
    "- compressed architecture design\n",
    "- model contains relatively small amount of parameters\n",
    "- achieve AlexNet-level accuracy on ImageNet dataset with 50x fewer parameters\n",
    "\n",
    "**Three advantages of small CNN architectures:**\n",
    "- require less communication across servers during distributed training.\n",
    "- require less bandwidth to export a new model from the cloud.\n",
    "- more feasible to deploy on customized hardware with limited memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References and Additional Information\n",
    "\n",
    "- [SqueezeNet Paper](https://arxiv.org/pdf/1602.07360.pdf)\n",
    "- [SqueezeNet architecture explanation](http://www.kdnuggets.com/2016/09/deep-learning-reading-group-squeezenet.html)\n",
    "- [1x1 convolutions explained](http://iamaaditya.github.io/2016/03/one-by-one-convolution/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architectural Design Strategies\n",
    "\n",
    "The authors outline 3 main strategies for reducing parameter size while maximizing accuracy\n",
    "\n",
    "### Strategy 1\n",
    "\n",
    ">  Make the network smaller by replacing 3x3 filters with 1x1 filters\n",
    "\n",
    "- conventional 3x3 replaced by 1x1 convolution filters\n",
    "- 1x1 filter has 9X fewer parameters than a 3x3 filter\n",
    "\n",
    "## Difference between 3x3 filters and 1x1 filters\n",
    "**3x3 filters**\n",
    "\n",
    "- larger spacial receptive field\n",
    "- captures spatial information of pixels close to each other.\n",
    "\n",
    "<img src=\"../../images/3x3_conv.gif\" width=\"200\">\n",
    "\n",
    "**1x1 filters**\n",
    "\n",
    "- looks at one pixel at the time\n",
    "- caputres relationships amongst its channels\n",
    "- equivalent to a fully connected layer along the channel dimension\n",
    "\n",
    "\n",
    "<img src=\"../../images/1x1_conv.gif\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 2\n",
    "\n",
    "> Reduce the number of inputs for the remaining 3x3 filters.\n",
    "\n",
    "- fewer inputs to conv layers result in fewer parameters\n",
    "- achieved by using only 1x1 filters prior to the 3x3 conv layer\n",
    "- called the squeeze layer (description in next section)\n",
    "- total number of parameters in 3x3 conv layer = (number of input channels) * (number of filters) * (3*3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 3\n",
    "\n",
    "> Downsample late in the network so that convolution layers have large activation maps.\n",
    "\n",
    "- make the most of smaller number of parameters and maximize accuracy\n",
    "- delaying downsampling late in the network, creates larger activation/feature maps\n",
    "- departure from more traditional architectures like the VGG network that use early downsampling\n",
    "- large activation maps results in a higher classification accuracy given the same number of parameters\n",
    "\n",
    "** VGG Architecure with early downsampling **\n",
    "<img src=\"../../images/vgg.png\" width=\"600\">\n",
    "\n",
    "**The two main ways to achieve downsampling:**\n",
    "\n",
    "- strides > 1 in the convolutional layers\n",
    "- pooling layers (eg max/average pooling)\n",
    "\n",
    "## General Strategy\n",
    "\n",
    "- Strategies 1 and 2 are about carefully decreasing the quantity of parameters in a CNN while attempting to preserve accuracy.\n",
    "- Strategy 3 is about maximizing accuracy on a limited budget of parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire Module\n",
    "\n",
    "**What is the Fire Module?**\n",
    "- building block used in the SqueezeNet\n",
    "- employs Strategies 1, 2, and 3\n",
    "- comprised of squeeze layers which have only 1x1 filters (strategy 1)\n",
    "- comprised of expand layers which have a mix of 1x1 and 3x3 convolution filters\n",
    "- number of filters in squeeze layer must be less than the expand layer (strategy 2)\n",
    "\n",
    "<img src=\"../../images/fire_module.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SqueezeNet Architecture\n",
    "\n",
    "** Layers breakdown **\n",
    "- layer 1: regular convolution layer\n",
    "- layer 2-9: fire module (squeeze + expand layer)\n",
    "- layer 10: regular convolution layer\n",
    "- layer 11: softmax layer\n",
    "\n",
    "** Architecure specifications **\n",
    "- gradually increase number of filters per fire module\n",
    "- max-pooling with stride of 2 after layer 1,4,8\n",
    "- average-pooling after layer 10\n",
    "- delayed downsampling with pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"../../images/SqueezeNet.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Lesson\n",
    "### Implementation of SqueezeNet\n",
    "- Implementation of Fire module\n",
    "- Implementation of full SqueezeNet model\n",
    "\n",
    "<img src=\"../../images/divider.png\" width=\"100\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
